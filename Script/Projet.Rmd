---
title: "Projet économétrie des panels"
author: "Le Cunff Ewen - Elisa Floch - Mandard Maël"
date: "Février 2023"
output: html_document
---


https://docplayer.fr/12368918-Econometrie-des-donnees-de-panel-avec-r.html

Faire stats des avec variable endogène et 2 ou 3 variables explicatives


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(nlme)
library(corrplot)
library(plm)
library(ggplot2)
library(systemfit)
library(rAmCharts)

```


```{r, include = FALSE}

getwd()

data <- read.table("../Data/qog_eureg_long_nov20.csv", sep = ",", header = TRUE, encoding = 'UTF-8')
data <- data[!is.na(data$eqi_score),]

# explication des variables : 
# year
# region_name
# eu_d2jan_t : Total population
# eu_d3area_t : Total surface area of a region as square kilometer
# eqi_norm_eqi : EQI index, min-max (0-100) standardized
# eu_b5n_eur_hab : Income of households (balance), constant Euro per inhabitant
# eu_empl_edltotal : Total employment rate for people between 15 and 34 years for all education levels (%)
# eqi_norm_corrupt : Corruption pillar, country centered and min-max (0-100) standardized
# eu_tour_nshotel : Number of nights spent at hotels and similar accommodations
# eu_rac_kil : Killed victims in road accidents, per million inhabitants
# eu_eduleave_t : Early leavers from education and training as a percentage of the population aged 18-24 with at most lower secondary education

#selection des variables
#variable à expliquer : eqi_norm
data <- data[,c("cname", "region_name", "year", "eqi_norm_eqi", "eu_d2jan_t", "eu_d3area_t", "eu_b5n_eur_hab","eu_empl_edltotal",
                "eu_hea_mdoc", "eu_tour_nshotel", "eu_rac_kil", "eu_eduleave_t")]

nrow(data)

#mise a jour de la surface pour avoir des donnees en 2017
df <- data[,c("region_name", "year", "eu_d3area_t")]
df <- df %>% filter(year == 2013)
df["year"] <- 2017

data <- data %>% left_join(df, 
           by=c('region_name'))

data <- data %>% select(region_name,year.x,eqi_norm_eqi,eu_d2jan_t,eu_d3area_t.y,eu_b5n_eur_hab,
                        eu_empl_edltotal,eu_hea_mdoc,eu_tour_nshotel,eu_rac_kil, eu_eduleave_t)

summary(data)

sum(is.na(data$eu_d3area_t.y))

#suppression des valeurs manquantes pour la surface
#suppression de la variable docteurs car trop de NA (106)
data <- data %>% filter(!is.na(data$eu_d3area_t.y)) %>%
                select(-eu_hea_mdoc)

table(data$year)

#remplacement des NA pour taux d'emploi et tourisme par leur mediane
data[is.na(data$eu_empl_edltotal),7] <- median(data$eu_empl_edltotal, na.rm = T)
data[is.na(data$eu_tour_nshotel),9] <- median(data$eu_tour_nshotel, na.rm = T)

summary(data)

#suppression des NA pour revenu par habitant, corruption et nombre de morts
data <- na.omit(data)

table <- data.frame(table(data$region_name))

reg_sup <- table[table$Freq != 3,1]
reg_sup

#suppression des regions pour lesquelles on n'a pas d'observations sur les 3 années
data <- data[!(data$region_name %in% reg_sup),]

table(data$year)

summary(data)

colnames(data) <- c("region", "annee", "EQI_norm", "pop", "surface", "revenu", "emploi",
                    "hotel", "meurtre", "education")

```

# **Introduction**
</br>


# **1) Statistiques descriptives**
</br>

```{r}
#on a 148 regions avec 3 observations par région

plot(data$annee,data$EQI_norm,xlab = "Année",ylab = "EQI normalisé", main = "EQI normalisé par année")
```


```{r}
data_ind <- groupedData(EQI_norm ~ annee|region, data,   outer = ~ region)
plot(data_ind, main = "EQI normalisé par année et par région")
```

```{r}
amBoxplot(EQI_norm~annee, data=data)
```

```{r}
ggplot(data) + aes(x= EQI_norm, y = ..density..) + 
  geom_histogram(bins = 30, fill = "red", color = "black") +
  geom_density() +
  ggtitle("Distribution de l'EQI normalisé") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("EQI normalisé") + 
  ylab("Densité")
```


```{r}
ggplot(data) + aes(x= pop, y = ..density..) + 
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  geom_density() +
  ggtitle("Distribution de la population") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Population") + 
  ylab("Densité")
```

```{r}
ggplot(data) + aes(x= revenu, y = ..density..) + 
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  geom_density() +
  ggtitle("Distribution du revenu") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Revenu") + 
  ylab("Densité")
```

```{r}
ggplot(data) + aes(x= emploi, y = ..density..) + 
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  geom_density() +
  ggtitle("Distribution du taux d'emploi") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Taux d'emploi") + 
  ylab("Densité")
```

```{r}
ggplot(data) + aes(x= meurtre, y = ..density..) + 
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  geom_density() +
  ggtitle("Distribution du nombre de meurtre") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("Nombre de meurtres") + 
  ylab("Densité")
```


```{r}
ggplot(data) + aes(x= education, y = ..density..) + 
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  geom_density() +
  ggtitle("Distribution") +
  theme(plot.title = element_text(hjust = 0.5)) +
  xlab("") + 
  ylab("Densité")
```




```{r}
matrixcorr<- data[,-c(1,2)]
mcor<-cor(matrixcorr)

#matrice des correlations
corrplot(mcor,type='upper', title = "Matrice des corrélations", mar=c(0,0,1,0))
```


```{r}
#transformation en donnees de panels
data_p <- pdata.frame(data, index = c("region", "annee"), drop.index = FALSE, row.names = TRUE)
pdim(data_p, 25)
head(data_p)

pdim(data_p)
```


```{r}
## decomposition de la variance 

###EQI
vartot_EQI <- sum((data_p$EQI_norm - mean(data_p$EQI_norm))^2)
vartot_EQI ##variabilité totale

var_withinEQI <- sum(Within(data_p$EQI_norm)^2)
var_withinEQI #variabilité within
var_withinEQI / vartot_EQI 
#variance intra = 10% de la variance totale

var_betweenEQI <- sum((Between(data_p$EQI_norm)-mean(data_p$EQI_norm))^2)
var_betweenEQI
var_betweenEQI / vartot_EQI
#variance inter = 90% de la variance totale

#peu de variabilité dans le temps pour une même région
#beaucoup de variabilité entre les régions pour une même année
```




Estimation modèles

```{r}
#pooled
form_pooled <- EQI_norm ~  pop + surface + revenu + emploi + meurtre + education
reg_pooled1 = lm(form_pooled ,  data=data_p)
summary(reg_pooled1)
```
```{r}
scr_pooled = sum(reg_pooled1$residuals^2)
scr_pooled
ddl_pooled = reg_pooled1$df.residual
ddl_pooled
```



```{r}
#modele heterogène
data$annee <- as.factor(data$annee)

reg_heter <- lm(EQI_norm ~ annee + pop:annee + surface:annee + revenu:annee + emploi:annee + meurtre:annee + education:annee - 1, data = data_p)

summary(reg_heter)

gr_MCO <- systemfit(EQI_norm ~ ., method="OLS", data=data_p)
summary(gr_MCO, residCov = FALSE, equations= FALSE)
summary(gr_MCO) #presentation differente
```
```{r}
scr_heter = sum(reg_heter$residuals^2)
scr_heter 

ddl_heter = reg_heter$df.residual
ddl_heter 
```


```{r}
#test anova

anova(reg_pooled1,reg_heter)
# rejet de H0, on retient le modèle non contraint, avec l'annee
#on retient le modele avec des annees heterogenes

pooltest(form_pooled, data = data_p, effect = "time", model = "pooling") # avec plm
#on rejette H0 : les annees n'ont pas le meme coefficient de pente
```


```{r}
## Modèles avec effets fixes temporels
# estimation within
formT = EQI_norm ~ annee +pop + surface + revenu + emploi + meurtre + education
reg_withinT = plm(formT ,  effect="time", model="within", data=data_p)

summary(reg_withinT)
summary(fixef(reg_withinT))

scr_withinT = sum(reg_withinT$residuals^2)
scr_withinT 

ddl_withinT = reg_withinT$df.residual
ddl_withinT 
```
```{r}
#test entre pooled et withinT
F_PP2W = ((scr_pooled-scr_withinT)/(ddl_pooled-ddl_withinT))/(scr_withinT/ddl_withinT)
F_PP2W

pvalue_PP2W = pf(F_PP2W,ddl_pooled-ddl_withinT,ddl_withinT,lower.tail=FALSE)
pvalue_PP2W
#on rejette H0
# on retient le modele a effets fixes temporels

```
```{r}
#test entre withinT et heterogene
F_PP3W = ((scr_withinT-scr_heter)/(ddl_withinT-ddl_heter))/(scr_heter/ddl_heter)
F_PP3W

pvalue_PP3W = pf(F_PP3W,ddl_withinT-ddl_heter,ddl_heter,lower.tail=FALSE)
pvalue_PP3W
#on accepte H0
# on retient le modele a effets fixes temporels
```


```{r}
###estimation du systeme d'?quations compose de 4 pays 
sub_data_p <- subset(data_p, region %in% c("Lombardia", "Toscana", "Emilia-Romagna", "Calabria"))

##methode SURE avec variance specifique ? chaque i et covariance differente de 0 = systemfit
gr_SUR <- systemfit(Homicide~ Police+RatioJ_V+alcool_litre+logPIB_PC + u+ Pop_Ur, method="SUR", data=sub_data_p)
##SUR iteratif option maxit=100 ici trop peu d'observations temporelles
summary(gr_SUR)

##methode MCO, suppose que covariance = 0 et variance speficique ? chaque i
gr_MCO <- systemfit(Homicide~ Police+RatioJ_V+alcool_litre+logPIB_PC + u+ Pop_Ur, method="OLS", data=sub_data_p)
summary(gr_MCO)

###avec plm , on suppose que variance identique et cov =0, coefficients les memes que gr_MCO mais std error different
reg_subpays = plm(Homicide~Pays + Police:Pays+RatioJ_V:Pays+alcool_litre:Pays+logPIB_PC:Pays + u:Pays+ Pop_Ur:Pays -1 , model = "pooling", data=sub_data_p)
coeftest(reg_subpays,vcovHC,type="HC3")
summary(reg_subpays)
###test d'independance 
pcdtest(reg_subpays) #pas le meme que dans stata, impose variance identique

```




